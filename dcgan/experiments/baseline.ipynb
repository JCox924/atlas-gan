{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline Model Training",
   "id": "6026e12a8e13774b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import the DCGAN model definitions using __import__\n",
    "dcgan_module = __import__('models.dcgan_baseline', fromlist=['build_generator', 'build_discriminator'])\n",
    "build_generator = dcgan_module.build_generator\n",
    "build_discriminator = dcgan_module.build_discriminator\n",
    "\n",
    "# Import other necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "# Rescale images to [-1, 1] for compatibility with the generator's tanh activation\n",
    "x_train = x_train * 2.0 - 1.0\n",
    "\n",
    "# Set hyperparameters\n",
    "latent_dim = 100\n",
    "img_shape = x_train.shape[1:]\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "num_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "# Build the generator and discriminator models\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(img_shape)\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Build the combined model by stacking the generator and discriminator.\n",
    "# Freeze the discriminator's weights when training the generator.\n",
    "discriminator.trainable = False\n",
    "noise_input = tf.keras.Input(shape=(latent_dim,))\n",
    "generated_img = generator(noise_input)\n",
    "validity = discriminator(generated_img)\n",
    "combined = tf.keras.Model(noise_input, validity)\n",
    "combined.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "                 loss='binary_crossentropy')\n",
    "\n",
    "# Function to visualize generated images during training\n",
    "def display_generated_images(generator, latent_dim, epoch, examples=16, dim=(4, 4), figsize=(4, 4)):\n",
    "    noise = np.random.normal(0, 1, (examples, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    # Rescale images from [-1, 1] to [0, 1] for display\n",
    "    generated_images = (generated_images + 1) / 2.0\n",
    "\n",
    "    fig, axs = plt.subplots(dim[0], dim[1], figsize=figsize, sharex=True, sharey=True)\n",
    "    cnt = 0\n",
    "    for i in range(dim[0]):\n",
    "        for j in range(dim[1]):\n",
    "            axs[i, j].imshow(generated_images[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.suptitle(f'Epoch {epoch}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Training loop for the DCGAN\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for batch in range(num_batches):\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "        real_imgs = x_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_imgs = generator.predict(noise)\n",
    "\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = combined.train_on_batch(noise, valid)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} [D loss: {d_loss[0]:.4f}, acc: {d_loss[1]*100:.2f}%] [G loss: {g_loss:.4f}]\")\n",
    "    \n",
    "    # Display generated images at the first epoch and every 5 epochs\n",
    "    if epoch == 1 or epoch % 5 == 0:\n",
    "        display_generated_images(generator, latent_dim, epoch)"
   ],
   "id": "f6b227a79b2dd570"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d6da0338b00741d"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
